import streamlit as st
from openai import OpenAI  # openai 2.x æ­£ç¡®å¯¼å…¥æ–¹å¼
from typing import List, Dict
import pydantic  # æ˜¾å¼å¯¼å…¥pydanticï¼Œé¿å…éšå¼ä¾èµ–é—®é¢˜

# éªŒè¯pydanticç‰ˆæœ¬ï¼ˆè°ƒè¯•ç”¨ï¼Œå¯åˆ é™¤ï¼‰
st.sidebar.caption(f"Pydanticç‰ˆæœ¬ï¼š{pydantic.__version__}")
st.sidebar.caption(f"OpenAIç‰ˆæœ¬ï¼š2.11.0")

# ===================== æ ¸å¿ƒç±»ï¼ˆé€‚é…openai 2.11.0ï¼‰ =====================
class AIModelClient:
    def __init__(self, api_key: str, base_url: str, default_model: str = "gpt-4o"):
        self.api_key = api_key
        self.base_url = base_url
        self.supported_models = ["gpt-4o", "deepseek-chat", "glm-4", "gemini-3-pro-preview", "doubao-seed-1-6-250615"]
        # åˆå§‹åŒ–å½“å‰æ¨¡å‹ï¼ˆæ ¡éªŒæ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ï¼‰
        self.current_model = default_model if default_model in self.supported_models else "gpt-4o"
        # å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆç”¨åˆ—è¡¨ä¿å­˜å†å²æ¶ˆæ¯ï¼‰
        self.conversation_history: List[Dict[str, str]] = [ {"role": "system", "content": "ä½ éœ€è¦ä½¿ç”¨å‘¨æ˜“ã€æ¢…èŠ±æ˜“æ•°ã€å¡”ç½—ç‰Œç­‰ä¹¦ç±è·Ÿå†å²ç®—å‘½ç»“æœï¼Œé€šè¿‡ç”¨æˆ·è¾“å…¥æˆ–é€‰æ‹©ç›¸å…³ä¿¡æ¯çš„æ–¹å¼ï¼Œäº§å‡ºç”¨æˆ·çš„ç®—å‘½ç»“æœï¼Œä¸ºç”¨æˆ·çš„æ„Ÿæƒ…ï¼Œäº‹ä¸šï¼Œå­¦ä¹ ï¼Œé£æ°´é€‰æ‹©ç­‰æ–¹é¢æä¾›æŒ‡å¯¼å’Œå¿ƒç†å®‰æ…°ã€‚"}]
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆopenai 2.x æ ‡å‡†å†™æ³•ï¼‰
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            timeout=100.0  # æ˜¾å¼æŒ‡å®šfloatç±»å‹ï¼Œé¿å…ç±»å‹æŠ¥é”™
        )

    def switch_model(self, new_model: str) -> bool:
        """åˆ‡æ¢å½“å‰ä½¿ç”¨çš„æ¨¡å‹"""
        if new_model in self.supported_models:
            self.current_model = new_model
            return True
        return False

    def send_message(self, user_message: str, keep_context: bool = True) -> str:
        """å‘é€æ¶ˆæ¯åˆ°å½“å‰æ¨¡å‹ï¼Œè¿”å›å“åº”å†…å®¹ï¼ˆé€‚é…openai 2.11.0ï¼‰"""
        # æ–°å¢ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
        user_msg = {"role": "user", "content": user_message.strip()}  # å»é™¤é¦–å°¾ç©ºæ ¼
        if keep_context:
            self.conversation_history.append(user_msg)
        else:
            self.conversation_history = [self.conversation_history[0], user_msg]

        try:
            # è°ƒç”¨å½“å‰é€‰ä¸­çš„æ¨¡å‹ï¼ˆopenai 2.x æ ‡å‡†è°ƒç”¨ï¼‰
            response = self.client.chat.completions.create(
                model=self.current_model,
                messages=self.conversation_history,
                timeout=100.0,
                temperature=0.7  # æ–°å¢å¯é€‰å‚æ•°ï¼Œæå‡å…¼å®¹æ€§
            )
            # æå–å“åº”å†…å®¹ï¼ˆopenai 2.x æ­£ç¡®å–å€¼ï¼‰
            assistant_content = response.choices[0].message.content.strip()
            assistant_msg = {"role": "assistant", "content": assistant_content}
            # ä¿ç•™åŠ©æ‰‹å“åº”åˆ°ä¸Šä¸‹æ–‡
            if keep_context:
                self.conversation_history.append(assistant_msg)
            return assistant_content
        except Exception as e:
            # è¯¦ç»†æŠ¥é”™ä¿¡æ¯ï¼Œæ–¹ä¾¿æ’æŸ¥
            error_info = f"æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼š{str(e)}\né”™è¯¯ç±»å‹ï¼š{type(e).__name__}"
            return error_info

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        self.conversation_history = [self.conversation_history[0]]

# ===================== Streamlité¡µé¢é…ç½® =====================
st.set_page_config(
    page_title="çŸ¥å‘½é˜",
    #page_icon="ğŸ¤–",
    layout="wide"
)

# ä¾§è¾¹æ ï¼šé…ç½®APIä¿¡æ¯ + æ¨¡å‹é€‰æ‹©
with st.sidebar:
    st.title("é…ç½®ä¸­å¿ƒ")
    #APIå¯†é’¥å’ŒBaseURLè¾“å…¥ï¼ˆå¯éšè—ï¼Œé¿å…æ³„éœ²ï¼‰
    api_key = st.text_input(
        "API Key",
        value="sk-mfyuzP5LaqpQ3XT6gKGWpqSyFv75vCG8r4JTAI6gPZff8vGa",
        type="password"
    )
    base_url = st.text_input(
        "Base URL",
        value="https://yunwu.ai/v1",
        help="è¯·ç¡®ä¿è¯¥åœ°å€æ”¯æŒopenai 2.xæ¥å£è§„èŒƒ"
    )

    # æ¨¡å‹é€‰æ‹©
    st.divider()
    st.subheader("æ¨¡å‹åˆ‡æ¢")
    supported_models = ["gpt-4o", "deepseek-chat", "glm-4", "gemini-3-pro-preview", "doubao-seed-1-6-250615"]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", supported_models)

    # æ¸…ç©ºå†å²æŒ‰é’®
    clear_btn = st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", type="secondary")

# ===================== åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆStreamlitä¼šè¯æ€ï¼‰ =====================
# ç”¨st.session_stateä¿å­˜å®¢æˆ·ç«¯å®ä¾‹ï¼Œé¿å…åˆ·æ–°é¡µé¢ä¸¢å¤±çŠ¶æ€
if "ai_client" not in st.session_state:
    # åˆå§‹åŒ–æ—¶æ ¡éªŒAPI Keyå’ŒBase URLéç©º
    if api_key and base_url:
        st.session_state.ai_client = AIModelClient(api_key=api_key, base_url=base_url)
    else:
        st.session_state.ai_client = None
        st.sidebar.error("âš ï¸ è¯·å¡«å†™æœ‰æ•ˆçš„API Keyå’ŒBase URLï¼")

# åˆ‡æ¢æ¨¡å‹ï¼ˆå¦‚æœç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹å’Œå½“å‰ä¸ä¸€è‡´ï¼‰
if st.session_state.ai_client and selected_model != st.session_state.ai_client.current_model:
    switch_success = st.session_state.ai_client.switch_model(selected_model)
    if switch_success:
        st.toast(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹ï¼š{selected_model}", icon="ğŸ”„")
    else:
        st.toast(f"âŒ åˆ‡æ¢å¤±è´¥ï¼ä¸æ”¯æŒæ¨¡å‹ï¼š{selected_model}", icon="âš ï¸")

# æ¸…ç©ºå†å²ï¼ˆç‚¹å‡»æŒ‰é’®è§¦å‘ï¼‰
if clear_btn and st.session_state.ai_client:
    st.session_state.ai_client.clear_history()
    st.toast("ğŸ—‘ï¸ å·²æ¸…ç©ºå¯¹è¯å†å²", icon="âœ…")

# ===================== èŠå¤©ç•Œé¢ =====================
st.title("AIç®—å‘½åŠ©æ‰‹")
if st.session_state.ai_client:
    st.caption(f"å½“å‰ä½¿ç”¨æ¨¡å‹ï¼š{st.session_state.ai_client.current_model}")
else:
    st.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§é…ç½®ä¸­å¿ƒå¡«å†™æœ‰æ•ˆçš„API Keyå’ŒBase URLï¼")

# å±•ç¤ºå†å²å¯¹è¯ï¼ˆä»ä¸Šä¸‹æ–‡åˆ—è¡¨ä¸­è¯»å–ï¼‰
if st.session_state.ai_client:
    # è¿‡æ»¤æ‰systemè§’è‰²çš„æ¶ˆæ¯ï¼Œåªå±•ç¤ºç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯
    for msg in st.session_state.ai_client.conversation_history:
        if msg["role"] in ["user", "assistant"]:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

# ç”¨æˆ·è¾“å…¥æ¡†ï¼ˆä»…å½“å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸæ—¶æ˜¾ç¤ºï¼‰
if st.session_state.ai_client and (user_input := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")):
    # å±•ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(user_input)

    # è°ƒç”¨æ¨¡å‹å¹¶å±•ç¤ºå“åº”
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            response = st.session_state.ai_client.send_message(user_input, keep_context=True)
        st.markdown(response)