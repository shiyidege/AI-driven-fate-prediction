import os
import gc
import time
from langchain_chroma import Chroma
from langchain_core.documents import Document
from rag.embeddings_transformers import HFTransformersEmbeddings

# 1. é…ç½®ç¯å¢ƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["CHROMA_TELEMETRY"] = "FALSE"
os.environ["ANONYMIZED_TELEMETRY"] = "FALSE"

# æ•°æ®åº“è·¯å¾„
PERSIST_DIR = "rag/knowledge_suanming/chroma_store"
# ç›®æ ‡å¤§æ–‡ä»¶è·¯å¾„
TARGET_FILE = "rag/knowledge_suanming/imported_fortune_telling.txt"

def main():
    print("ğŸš€ å¯åŠ¨æä½å†…å­˜æ„å»ºæ¨¡å¼...")
    
    # 2. åŠ è½½ Embedding æ¨¡å‹ (å†…å­˜æ¶ˆè€—å¤§æˆ·ï¼Œå…ˆåŠ è½½)
    print(" -> æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹ (BGE-Small)...")
    embeddings = HFTransformersEmbeddings(
        model_name="BAAI/bge-small-zh-v1.5",
        device="cpu"
    )

    # 3. åˆå§‹åŒ–æ•°æ®åº“
    print(f" -> è¿æ¥æ•°æ®åº“: {PERSIST_DIR}")
    vector_store = Chroma(
        collection_name="suanming_kb",
        embedding_function=embeddings,
        persist_directory=PERSIST_DIR,
    )

    if not os.path.exists(TARGET_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {TARGET_FILE}")
        return

    print(f" -> å¼€å§‹æµå¼å¤„ç†æ–‡ä»¶: {TARGET_FILE}")
    
    # 4. é€è¡Œè¯»å– + å°æ‰¹æ¬¡å†™å…¥
    batch_lines = []
    batch_size = 20  # æ¯æ¬¡åªå¤„ç† 20 æ¡é—®ç­”ï¼ˆéå¸¸ä¿å®ˆï¼‰
    total_processed = 0

    with open(TARGET_FILE, 'r', encoding='utf-8', errors='ignore') as f:
        current_text_block = ""
        
        for line in f:
            line = line.strip()
            # ç®€å•æ‹¼æ¥
            current_text_block += line + "\n"
            
            # é‡åˆ°åˆ†éš”ç¬¦ï¼ˆå‡è®¾ä½ çš„æ•°æ®æ˜¯ç”¨ ----- åˆ†éš”çš„ï¼‰æˆ–è€…ç§¯ç´¯äº†ä¸€å®šé•¿åº¦
            if "----------" in line or len(current_text_block) > 500:
                batch_lines.append(current_text_block)
                current_text_block = "" # é‡ç½® buffer

            # å½“ç§¯æ”’å¤Ÿäº† batch_size ä¸ªå°å—ï¼Œå°±å†™å…¥ä¸€æ¬¡
            if len(batch_lines) >= batch_size:
                # è½¬æ¢æˆ Document å¯¹è±¡
                docs = [Document(page_content=txt, metadata={"source": "fortune_telling_dataset"}) for txt in batch_lines]
                
                try:
                    vector_store.add_documents(docs)
                    total_processed += len(docs)
                    print(f"    v å·²å­˜å…¥ {total_processed} æ¡æ•°æ®... (å†…å­˜æ¸…ç†)")
                except Exception as e:
                    print(f"    [WARN] å†™å…¥å¤±è´¥: {e}")
                
                # === å…³é”®ï¼šå½»åº•é‡Šæ”¾å†…å­˜ ===
                del docs
                batch_lines = [] # æ¸…ç©ºåˆ—è¡¨
                gc.collect()     # å¼ºåˆ¶åƒåœ¾å›æ”¶
                time.sleep(0.1)  # æ­‡ä¸€ä¼šï¼Œç»™ CPU å–˜æ¯æ—¶é—´

        # 5. å¤„ç†æœ€åå‰©ä½™çš„
        if batch_lines:
            print(" -> æ­£åœ¨å†™å…¥æœ€åå‰©ä½™æ•°æ®...")
            docs = [Document(page_content=txt, metadata={"source": "fortune_telling_dataset"}) for txt in batch_lines]
            vector_store.add_documents(docs)
            print("    v å®Œæˆï¼")

    print("-" * 30)
    print(f"âœ… æ„å»ºå®Œæˆï¼å…±å­˜å…¥çº¦ {total_processed} æ¡è®°å½•ã€‚")

if __name__ == "__main__":
    main()